{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Document Classification Custom Skill\n",
    "This tutorial shows how to train a document classification custom skill for Cognitive Search. We will use the 20newsgroups dataset provided by scikit-learn as our sample dataset.\n",
    "\n",
    "For more information, please see the [AML](https://docs.microsoft.com/en-us/azure/machine-learning/service/) or [Cognitive Search](https://docs.microsoft.com/en-us/azure/search/cognitive-search-resources-documentation) documentation. This notebook is based off the MNIST Image Classification tutorial found [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/tutorial-train-models-with-aml) as well as this [documentation](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-track-experiments) on tracking experiments locally. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.0 Important Variables you need to set for this tutorial\n",
    "\n",
    "Enter your workspace, resource and subscription credentials below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Service Workspace configuration\n",
    "my_workspace_name = ''\n",
    "my_azure_subscription_id = ''\n",
    "my_resource_group = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Import packages\n",
    "If this is your first time using AML, please see this quickstart to get your environment set up: https://docs.microsoft.com/azure/machine-learning/service/quickstart-create-workspace-with-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License.\n",
    "\n",
    "import azureml\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Connect to Workspace\n",
    "Create a workspace object. If you already have a workspace and a config.json file you can use `ws = Workspace.from_config()` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ws = Workspace.get(name = my_workspace_name, resource_group = my_resource_group, subscription_id = my_azure_subscription_id)\n",
    "print(ws.name, ws.location, ws.resource_group, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Create Experiment\n",
    "Create an experiment to track the runs in your workspace. A workspace can have muliple experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'newsgroup-classification'\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Import data for classification\n",
    "The 20newsgroups dataset is available through scikit-learn and can be imported as shown below.\n",
    "\n",
    "To use your own data instead, simply edit the cell below to populate your data into `X_train`, `y_train`, `X_text`, and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "X_train = newsgroups_train.data\n",
    "y_train = [categories[x] for x in newsgroups_train.target]\n",
    "\n",
    "X_test = newsgroups_test.data\n",
    "y_test = [categories[x] for x in newsgroups_test.target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 Train and Score model locally\n",
    "For this tutorial, the model will be trained locally and results will be logged to AML.\n",
    "\n",
    "A scikit-learn pipeline is used to transform the data into a tfidf matrix and then classify the results using a [BaggingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Create a run object in the experiment\n",
    "run = exp.start_logging()\n",
    "\n",
    "# Creating pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words = 'english', ngram_range= (1, 2))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('bc', BaggingClassifier(n_estimators=20))\n",
    "])\n",
    "\n",
    "# Fitting pipeline\n",
    "print(\"Started Training Model\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print('Predicting against the test data')\n",
    "pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Results:\")\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "scores = precision_recall_fscore_support(y_test, pred, average='micro')\n",
    "\n",
    "run.log('precision', scores[0])\n",
    "run.log('recall', scores[1])\n",
    "run.log('fscore', scores[2])\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "import joblib\n",
    "joblib.dump(value=pipeline, filename='outputs/newsgroup_classifier.pkl')\n",
    "\n",
    "# Complete the run\n",
    "run.complete()\n",
    "\n",
    "print()\n",
    "print('The model has been exported to `outputs/newsgroup_classifier.pkl` for use in the next tutorial.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
